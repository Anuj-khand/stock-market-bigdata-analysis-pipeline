# ğŸ“ˆ Stock Market Real-Time ETL Pipeline using Kafka + AWS

This project simulates a *real-time stock market streaming pipeline* using *Apache Kafka* and AWS services.  
Stock market events are produced continuously, streamed through Kafka, stored in an *Amazon S3 data lake, cataloged using **AWS Glue, queried with **Amazon Athena, and visualized using **Amazon QuickSight*.

---

## ğŸš€ Project Objective
To build an end-to-end *big data streaming pipeline* that demonstrates real-time ingestion, storage, cataloging, querying, and dashboarding.

---

## ğŸ—ï¸ Architecture
Producer â†’ Kafka (EC2) â†’ Consumer â†’ S3 â†’ Glue Crawler â†’ Athena â†’ QuickSight Dashboard

ğŸ“Œ Architecture Diagram:  
![Architecture](architecture/architecture.png)

---

## ğŸ› ï¸ Tech Stack
- *Python*
- *Apache Kafka*
- *AWS EC2*
- *Amazon S3*
- *AWS Glue (Crawler + Data Catalog)*
- *Amazon Athena*
- *Amazon QuickSight*

---

## ğŸ“‚ Repository Structure

```bash
.
â”œâ”€â”€ producer/
â”‚   â”œâ”€â”€ kafka_producer_realtime.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ config.example.env
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ consumer/
â”‚   â”œâ”€â”€ kafka_consumer_to_s3.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ config.example.env
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ glue/
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ crawler_config.md
â”‚   â”œâ”€â”€ table_schema.md
â”‚   â”œâ”€â”€ permissions.md
â”‚   â””â”€â”€ athena_queries.sql
â”‚
â””â”€â”€ architecture/
    â”œâ”€â”€ architecture.png
    â””â”€â”€ dashboard_preview.png
